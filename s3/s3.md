### aws cli s3 简易试玩
关于安装aws cli见官网 [https://docs.aws.amazon.com/cli/latest/userguide/installing.html](https://docs.aws.amazon.com/cli/latest/userguide/installing.html)

安装完毕就开始玩吧。

**需要注意：**

```
The AWS CLI signs requests on your behalf, and includes a date in the signature. 
Ensure that your computer's date and time are set correctly;
if not, the date in the signature may not match the date of the request, and AWS rejects the request.
```

**开始配置认证权限：**

用aws configure来做配置即可，aliyun也是。
比如`osscmd config --id=n8OtIb*****XhmE --key cxfOU3*****OZLlIn`

如果拥有多个profiles的话，可以用`--profile`参数。记得之前在aliyun我准备了好几份`.credentials`配置用来做到不同region之间的快速切换。

配置简单易上手，我这是日本东京(不知道现在热不热)的S3，属于亚太地区，名叫ap-northeast-1。
![](https://github.com/crabsheen/cloud/blob/master/s3/aws.png?raw=true)

Home下面会有2个文件`.aws/credentials` 和 `.aws/config`，即填入的参数。

ps:出于使用安全考虑，不建议直接上root，建议用amazon IAM 来做新建账户**仅仅赋予S3的full permission**，创建完毕需要尽快下载.csv，内部有具体的key-pair，也就是aws configure的输入。

```
做个示例，用只有S3操作权限的认证企图去描述一个我的ec2实例时返回UnauthorizedOperation。
[root@ip-172-31-42-16 ~]# aws s3 ls s3://duweistore                                    
                           PRE mogujie.com/
2018-03-16 09:31:43     812245 DevOps_Fundamentals_20171206.pdf
2018-04-01 11:56:49         31 duwei-presign.txt
2018-03-30 08:39:17         29 presign.txt
2018-03-29 08:09:17         12 stream.txt

[root@ip-172-31-42-16 ~]# aws ec2 describe-instances --instance-ids i-073c0bb766c92d3dd

An error occurred (UnauthorizedOperation) when calling the DescribeInstances operation: You are not authorized to perform this operation.
```

关于认证权限的查找顺序：

```
aws cli使用AK配置时，looks for的顺序依次为
command line options ——> environment variables ——> credentials file 
——> config file ——> Container credentials ——> Instance profile credentials
```

**aws s3 high-level command，通用例子少一些，多举点以前没遇到的**

1. 有递归操作，`--recursive`还是比较人性化的，可以删除目录下的目录及文件了。

	```
	[root@ip-172-31-42-16 ~]# aws s3 rm s3://duweistore/mogujie.com/nginx/ --recursive
	delete: s3://duweistore/mogujie.com/nginx/bin/nginxctl
	```
	
2. 有`Exclude and Include Filters`，支持pattern symbols 来做一些exclude 或 include 不过有一点务必要注意的是先后顺序很重要。	
PS: When there are multiple filters, the rule is the filters that appear later in the command  take precedence  over filters that appear earlier in the command.
	默认是全部inclueded的,可以理解为后面第一个参数默认就是`--include “*”` ，也就是说此时你想只把`/tmp/foo/*.jpg`这些模糊匹配的jpg文件都拷贝过去，如果只写`include “*.jpg”` 是错误的，因为本质上默认是all included，下面才是正确姿势。
	
	`aws s3 cp /tmp/foo/ s3://duweistore/ --recursive --exclude "*" --include "*.jpg"`
3. 有别于普通Linux环境下的操作，在对目录操作时候，如果不做显式的的排除策略，是会涉及到目录下的隐藏文件，通常我们在Linux环境在对一个目录做cp -rp的时候不会操作到隐藏文件的。比如会将`.wokao`也往s3上挪，稍微注意下比如敏感信息。
	```
	[root@ip-172-31-42-16 mapp]# aws s3 cp /home/mapp/ s3://duweistore/mogujie.com/ --recursive
	upload: ./.wokao to s3://duweistore/mogujie.com/.wokao
	upload: nginx/bin/nginxctl to s3://duweistore/mogujie.com/nginx/bin/nginxctl
	```
4. 小缺点，参数没有简写，得写全，也算好事，看着很清晰明了。

	```
	aws s3 ls --human-readable --summarize --recursive  s3://duweistore          
	2018-03-16 09:31:43  793.2 KiB DevOps_Fundamentals_20171206.pdf
	2018-03-28 10:30:16    0 Bytes mogujie.com/
	2018-03-28 10:31:49    2.5 MiB mogujie.com/jca457.jar
	```
5. `--request-payer` 由请求的发起方来为资源使用而付费。
	
	```
	具体含义是由申请方支付请求和数据传输的费用，但是存储的付费仍旧由owner来承担。
	只能在bucket级别做设置，不可以对bucket内的具体objects做request-payer设置。
	目前有4种额外的情况下，仍旧需要由bucket owner来承担费用，比如用户请求头部未包含x-amz-request-payer这种错误请求。
	
	# aws s3api get-bucket-request-payment --bucket request4pay
	{
    		"Payer": "Requester"
	}
	#示例
	# aws s3api get-object --bucket request4pay --key DevOps_Fundamentals_20171206.pdf --request-payer wokao duwei.pdf
	{
    	"AcceptRanges": "bytes", 
    	"ContentType": "application/pdf", 
    	"LastModified": "Sun, 08 Apr 2018 08:16:27 GMT", 
    	"ContentLength": 812245, 
    	"ETag": "\"2d126e64660e60c2e0e25385eaca35ce\"", 
    	"Metadata": {}
	}
	
	# ll -t
	total 812
	-rw-r--r--. 1 root root 812245 Apr  8 08:20 duwei.pdf
	
	#再补充个示例
	[root@ip-172-31-42-16 ~]# aws s3 cp --request-payer requester s3://arxiv/pdf/arXiv_pdf_1001_001.tar /tmp/arXiv_pdf_1001_001.tar    
	download: s3://arxiv/pdf/arXiv_pdf_1001_001.tar to ../tmp/arXiv_pdf_1001_001.tar
	
	```
6. 在upload的时候同时设置acl权限，比如`--acl public-read-write`，当然前提是操作用户先要具备`s3:PutObjectAcl`权限，否则白搭。
7. 为某个对象grants 权限给予 指定的user(email address)
	
	```
	aws s3 cp file.txt s3://mybucket/ --grants read=uri=http://acs.amazonaws.com/groups/global/AllUsers full=emailaddress=duwei@mogujie.com
	```
8. `aws s3 mb` 默认在当前配置文件的region区域内创建bucket，也可以用`--region`来指定要创建bucket的目标region。
9. `pre-signed`预签名玩法
	
	```
	首先说适用场景，简单的说是可以授予任何人有上传对象的临时权限，给他人一个基于时间(比如1个小时)的权限认证。
	我想的一个场景是开放给用户甚至其他业务临时具备自主上传对象的权限。
	All objects and buckets by default are private. 
	The pre-signed URLs are useful if you want your user/customer 
	to be able to upload a specific object to your bucket, 
	but you don't require them to have AWS security credentials or permissions.
	
	具体玩法，官方示例，此处生成一段pre-signed url。
        private static String bucketName = "duweistore";
        private static String objectKey  = "duwei-presign.txt";

        public static void main(String[] args) throws IOException {
                AmazonS3 s3client = new AmazonS3Client(new ProfileCredentialsProvider());

                try {

                        System.out.println("Generating pre-signed URL.");
                        java.util.Date expiration = new java.util.Date();
                        long milliSeconds = expiration.getTime();
                        milliSeconds += 1000 * 60 * 60; // Add 1 hour.
                        expiration.setTime(milliSeconds);

                        GeneratePresignedUrlRequest generatePresignedUrlRequest =
                                    new GeneratePresignedUrlRequest(bucketName, objectKey);
                        generatePresignedUrlRequest.setMethod(HttpMethod.PUT);
                        generatePresignedUrlRequest.setExpiration(expiration);

                        URL url = s3client.generatePresignedUrl(generatePresignedUrlRequest); 
	
	##完整实例，生成预签名url然后从任何地方发起通过url上传文件到S3
	[root@ip-172-31-42-16 java]# java GeneratePresignedUrlAndUploadObject
	Generating pre-signed URL.
	Pre-Signed URL = https://duweistore.s3.amazonaws.com/duwei-presign.txt?AWSAccessKeyId=AKIAIS65M6PBDJGKAJCQ&Expires=1522587361&Signature=UNld%2FrFYxD%2FQ9wnzx43aNuagJj8%3D
	
	[root@ip-172-31-42-16 java]# cat /tmp/fuck 
	curl presign test to amazon s3
	
	##curl 上传
	[root@ip-172-31-42-16 java]# curl -v --upload-file "/tmp/fuck" "https://duweistore.s3.amazonaws.com/duwei-presign.txt?AWSAccessKeyId=AKIAIS65M6PBDJGKAJCQ&Expires=1522587361&Signature=UNld%2FrFYxD%2FQ9wnzx43aNuagJj8%3D"         
	* About to connect() to duweistore.s3.amazonaws.com port 443 (#0)
	*   Trying 52.219.0.1...
	* Connected to duweistore.s3.amazonaws.com (52.219.0.1) port 443 (#0)
	* Initializing NSS with certpath: sql:/etc/pki/nssdb
	*   CAfile: /etc/pki/tls/certs/ca-bundle.crt
  	CApath: none
	* SSL connection using TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256
	* Server certificate:
	*       subject: CN=*.s3.amazonaws.com,O=Amazon.com Inc.,L=Seattle,ST=Washington,C=US
	*       start date: Sep 22 00:00:00 2017 GMT
	*       expire date: Jan 03 12:00:00 2019 GMT
	*       common name: *.s3.amazonaws.com
	*       issuer: CN=DigiCert Baltimore CA-2 G2,OU=www.digicert.com,O=DigiCert Inc,C=US
	> PUT /duwei-presign.txt?AWSAccessKeyId=AKIAIS65M6PBDJGKAJCQ&Expires=1522587361&Signature=UNld%2FrFYxD%2FQ9wnzx43aNuagJj8%3D HTTP/1.1
	> User-Agent: curl/7.29.0
	> Host: duweistore.s3.amazonaws.com
	> Accept: */*
	> Content-Length: 31
	> Expect: 100-continue
	> 
	< HTTP/1.1 100 Continue
	* We are completely uploaded and fine
	< HTTP/1.1 200 OK
	< x-amz-id-2: KQuf3Z+B2QelUbuyhq2CmCetByE8jR+S1rGwTlIrT/xQH0KoOQ9vxhIuKXaWbGlBxgfV+oMZcm0=
	< x-amz-request-id: BDCF21AF72EDA30C
	< Date: Sun, 01 Apr 2018 11:56:49 GMT
	< x-amz-version-id: XNdJ4.81pq_lqY1XHfKcEaCVQwLE6fNI
	< ETag: "f57cee952cfddf4e1537509287a6650f"
	< Content-Length: 0
	< Server: AmazonS3
	< 
	* Connection #0 to host duweistore.s3.amazonaws.com left intact
	
	##打印输出到std out，屏幕。
	[root@ip-172-31-42-16 java]# aws s3 cp s3://duweistore/duwei-presign.txt -
	curl presign test to amazon s3
	``` 
10. `aws s3 sync`类似于rsync 做本地和远程的同步 or 远程不同目录的同步。
11. `aws s3 website s3://duweistore2 --index-document xxx.html --error-document yyy.html`将bucket快速地作为一个static website对外服务。注意bucket的策略是赋予Anyone具有s3:GetObject的Action。

	```
	[root@ip-172-31-42-16 ~]# curl http://duweistore2.s3-website-ap-northeast-1.amazonaws.com/presign.txt -i
	HTTP/1.1 200 OK
	x-amz-id-2: LCE5XjyJtcvENsVMC3sJoARqCwup7VoIOf1uN3zV07L6D3tLMiDqbbvXNcQ114pEqRFD/IrDs9A=
	x-amz-request-id: 504D58929CA1257C
	Date: Mon, 02 Apr 2018 08:30:42 GMT
	Last-Modified: Fri, 30 Mar 2018 09:53:09 GMT
	ETag: "18c6bdaa55a98bb617f199bdd0a2c9b2"
	Content-Type: binary/octet-stream
	Content-Length: 29
	Server: AmazonS3

	This text uploaded as object.
	``` 
12. 关于定价`Pay only for what you use`，见[https://aws.amazon.com/s3/pricing/](https://aws.amazon.com/s3/pricing/)
	主要取决于bucket所在region对应的location(东京比北美贵) 以及存储类别 以及 资源使用量。
	关于使用资源维度有`Storage, Request,Storage Management,Data Transfer,Cross-Region Replication`等细分的计费策略。
